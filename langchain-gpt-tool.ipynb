{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Union\n",
    "import zipfile\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
    "# LLM wrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import OpenAI\n",
    "# Conversational memory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "# Embeddings and vectorstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Vectorstore Index\n",
    "index_name = 'podcasts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhoAmIResponse(username='4de3c64', user_label='default', projectname='9dde414')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file in the current directory\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\") or \"PINECONE_API_KEY\"\n",
    "env = os.getenv(\"PINECONE_ENVIRONMENT\") or \"PINECONE_ENVIRONMENT\"\n",
    "\n",
    "pinecone.init(api_key=api_key, environment=env)\n",
    "pinecone.whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['podcasts']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code block if you want to clear the index, or if the index doesn't exist yet\n",
    "\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "# if index_name in pinecone.list_indexes():\n",
    "#     pinecone.delete_index(index_name)\n",
    "\n",
    "# # Creates new index\n",
    "# pinecone.create_index(name=index_name, dimension=1536)\n",
    "# index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# # Confirm our index was created\n",
    "# pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a Search tool - note you'll need to have set SERPAPI_API_KEY as an environment variable as per the above instructions\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "# Define a list of tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the prompt with input variables for tools, user input and a scratchpad for the model to record its workings\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        \n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "            \n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        \n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        \n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "    \n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        \n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        \n",
    "        # If it can't parse the output it raises an error\n",
    "        # You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        \n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "    \n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate our LLM - default is 'gpt-3.5-turbo'\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Using tools, the LLM chain and output_parser to make an agent\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    # We use \"Observation\" as our stop sequence so it will stop when it receives Tool output\n",
    "    # If you change your prompt template you'll need to adjust this as well\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the agent that will respond to our queries\n",
    "# Set verbose=True to share the CoT reasoning the LLM goes through\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Hmm, I be not sure of the answer to that one.\n",
      "Action: Search\n",
      "Action Input: \"Canada population 2023\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe current population of Canada is 38,680,894 as of Sunday, May 7, 2023, based on Worldometer elaboration of the latest United Nations data. Canada 2020 population is estimated at 37,742,154 people at mid year according to UN data.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAhoy, that be the answer I was lookin' for!\n",
      "Final Answer: According to me search, the population of Canada as of 2023 be 38,680,894 Arg!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'According to me search, the population of Canada as of 2023 be 38,680,894 Arg!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Hmm, I'm not sure what this question means. I better search for more information.\n",
      "Action: Search\n",
      "Action Input: \"2022 events\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m8. Humanitarian Crises Deepen · 7. Latin America Moves Left. · 6. Iranians Protest. · 5. COVID Eases. · 4. Inflation Returns. · 3. Climate Change ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNone of these seem to answer the question. I better try a different search.\n",
      "Action: Search\n",
      "Action Input: \"What is happening in 2022?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mMajor war returned to Europe, with the attendant threats of nuclear strikes, and the door closed firmly shut on the U.S. policy of strategic ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAhoy, that's not what I was looking for. Let me try one more search.\n",
      "Action: Search\n",
      "Action Input: \"2022 calendar\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mUnited States 2022 – Calendar with American holidays. Yearly calendar showing months for the year 2022. Calendars – online and print friendly – for any year ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mArrr, I see now. The question was asking about the year 2022. \n",
      "Final Answer: In 2022, there be a calendar with American holidays. Arg!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In 2022, there be a calendar with American holidays. Arg!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many in 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template which can interpolate the history\n",
    "template_with_history = \"\"\"You are SearchGPT, a professional search engine who provides informative answers to users. Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to give detailed, informative answers\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    # The history template includes \"history\" as an input variable so we can interpolate it into the prompt\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the memory with k=2 to keep the last two turns\n",
    "# Provide the memory to the agent\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the most recent population data for Canada.\n",
      "Action: Search\n",
      "Action Input: \"Canada population 2023\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe current population of Canada is 38,680,894 as of Sunday, May 7, 2023, based on Worldometer elaboration of the latest United Nations data. Canada 2020 population is estimated at 37,742,154 people at mid year according to UN data.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the most recent population data for Canada.\n",
      "Final Answer: As of May 7, 2023, the population of Canada is 38,680,894.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As of May 7, 2023, the population of Canada is 38,680,894.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current population of Mexico\n",
      "Action: Search\n",
      "Action Input: \"current population of Mexico\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mMexico, officially the United Mexican States, is a country in the southern portion of North America. It is bordered to the north by the United States; to the south and west by the Pacific Ocean; to the southeast by Guatemala, Belize, and the Caribbean Sea; and to the east by the Gulf of Mexico.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThat's not the answer to the question, I need to refine my search\n",
      "Action: Search\n",
      "Action Input: \"population of Mexico 2023\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe current population of Mexico is 132,776,091 as of Sunday, May 7, 2023, based on Worldometer elaboration of the latest United Nations data.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The current population of Mexico as of May 7, 2023 is 132,776,091.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current population of Mexico as of May 7, 2023 is 132,776,091.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"how about in mexico?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This question requires information about both the men's and women's singles champions at Wimbledon 2022.\n",
      "Action: Search\n",
      "Action Input: \"Wimbledon 2022 men's and women's singles champions\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mElena Rybakina defeated Ons Jabeur in the final, 3–6, 6–2, 6–2 to win the ladies' singles tennis title at the 2022 Wimbledon Championships.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe search result only provided information about the women's singles champion. I need to search again to find the men's singles champion.\n",
      "Action: Search\n",
      "Action Input: \"Wimbledon 2022 men's singles champion\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mchampion Novak Djokovic\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Elena Rybakina won the ladies' singles title and Novak Djokovic won the men's singles title at the 2022 Wimbledon Championships.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Elena Rybakina won the ladies' singles title and Novak Djokovic won the men's singles title at the 2022 Wimbledon Championships.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"Who won Wimbledon 2022 for men and women's title?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
